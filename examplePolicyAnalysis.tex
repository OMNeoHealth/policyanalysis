\documentclass[11pt,a4paper]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=2cm]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Introduction to the use of R for applying content/sentiment anlaysis for OMNeoHealth's policy analysis component},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Introduction to the use of R for applying content/sentiment anlaysis for
OMNeoHealth's policy analysis component}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{}
  \preauthor{}\postauthor{}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{16/05/2018}


\begin{document}
\maketitle

\hypertarget{conceptual-overview-of-proposed-omneohealth-policy-analysis-approach-using-content-analysis}{%
\subsection{Conceptual overview of proposed OMNeoHealth policy analysis
approach using content
analysis}\label{conceptual-overview-of-proposed-omneohealth-policy-analysis-approach-using-content-analysis}}

\hypertarget{examples-of-how-to-use-this-approach}{%
\subsection{Examples of how to use this
approach}\label{examples-of-how-to-use-this-approach}}

For this example we will use the text data of Papua New Guinea's Alotau
Accord of 2014 available in the \texttt{papuanewguinea} data package of
the OMNeoHealth GitHub project.

First, install the \texttt{papuanewguinea} data package:

~

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#}
\CommentTok{# Install devtools package in R }
\CommentTok{# (allows for installation of packages from GitHub)}
\CommentTok{#}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\CommentTok{#}
\CommentTok{# Install papuanewguinea data package in R via GitHub}
\CommentTok{#}
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"OMNeoHealth/papuanewguinea"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

~

Once installed, the Alotau Accord of 2014 is now available for us to
use. the object name for the text data is \texttt{alotau\_accord\_2014}

You can examine the data by simply typing in the name of the data in R:

~

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as_tibble}\NormalTok{(papuanewguinea}\OperatorTok{::}\NormalTok{alotau_accord_}\DecValTok{2014}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 477 x 2
##     line text                                                             
##    <int> <chr>                                                            
##  1     1 "                                   CONTENTS"                    
##  2     2 Glossary of Terms                                               ~
##  3     3 Message from the Minister of Health and HIV/AIDS                ~
##  4     4 Foreword from the Secretary for the National Department of Healt~
##  5     5 What is the Alotau Accord?                                      ~
##  6     6 Why is there a need for Free Primary Health Care and Subsidized ~
##  7     7 Specialist Services?                                             
##  8     8 What is Primary Health Care and Subsidized Specialist Services? ~
##  9     9 What is in this Policy?                                         ~
## 10    10 What Are Facility Levels?                                       ~
## # ... with 467 more rows
\end{verbatim}

~

You will notice that the \texttt{alotau\_accord\_2014} dataset is
structured as a dataframe with each row corresponding to each of the
lines of text in the actual Alotau Accord of 2014 document.

To be able to work with this text data further using content analysis or
sentiment analysis, we need to \texttt{tokenise} the dataset. This means
we need to break up the text data into \texttt{tokens} - a meaningful
unit of text, most often a word, that we are interested in using for
further analysis. To do this, we will use the \texttt{tidytext} package.
Install and load the package in R by issuing the following commands:

~

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"tidytext"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(tidytext)}
\end{Highlighting}
\end{Shaded}

~

The \texttt{tidytext} package has the \texttt{unnest\_tokens()} function
that basically tokenises the dataset. This can be applied to the
\texttt{alotau\_accord\_2014} dataset as follows:

~

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alotauDF <-}\StringTok{ }\KeywordTok{unnest_tokens}\NormalTok{(}\DataTypeTok{tbl =}\NormalTok{ papuanewguinea}\OperatorTok{::}\NormalTok{alotau_accord_}\DecValTok{2014}\NormalTok{,}
                          \DataTypeTok{output =}\NormalTok{ word, }
                          \DataTypeTok{input =}\NormalTok{ text)}
\end{Highlighting}
\end{Shaded}

~

Let's now examine what the resulting \texttt{alotauDF} data object looks
like:

~

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as_tibble}\NormalTok{(alotauDF)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4,652 x 2
##     line word    
##    <int> <chr>   
##  1     1 contents
##  2     2 glossary
##  3     2 of      
##  4     2 terms   
##  5     2 2       
##  6     3 message 
##  7     3 from    
##  8     3 the     
##  9     3 minister
## 10     3 of      
## # ... with 4,642 more rows
\end{verbatim}

~

The \texttt{alotauDF} data object is now a dataframe of all the words in
the actual Alotau Accord of 2014.

Given such a data structure, we can now potentially perform various
types of analysis based on the word content of the accord. This analysis
should be guided by the research questions that need to be answered by
the project.

The example above treats the policy document as a collection of words.
Depending on the research question/s, you may want to tokenise the
policy document/s into sentences, paragraphs, n-grams (collection of
consecutive words) on which you can perform various types of analysis.

I would recommend the book \textbf{\emph{Text Mining with R}} as our
main reference guide for doing the content/sentiment analysis in R. It
is available to read online as an online book at
\url{https://www.tidytextmining.com}.


\end{document}
